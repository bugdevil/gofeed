package main

import (
	"log"
	"net/http"
	"net/url"
	"regexp"
	"strconv"
	"strings"
	"time"
)

// return later time
func GetLaterTimeStr(a, b string) (result string, err error) {
	timeA, err := http.ParseTime(a)
	if nil != err {
		log.Printf("[ERROR] failed to parse string %s as http time", a)
		return
	}
	timeB, err := http.ParseTime(b)
	if nil != err {
		log.Printf("[ERROR] failed to parse string %s as http time", b)
		return
	}

	if timeA.After(timeB) {
		result = a
	} else {
		result = b
	}

	return
}

// normalize url
func NormalizeURLStr(rawString string) string {
	if !strings.HasPrefix(rawString, HTTP_SCHEME) && !strings.HasPrefix(rawString, HTTPS_SCHEME) {
		rawString = HTTP_SCHEME + rawString
	}
	return rawString
}

// FeedTarget should be generated by ParseJsonConfig function
// find index regexp
func FindIndexRegs(feedTar *FeedTarget, feedURL *url.URL) []*regexp.Regexp {
	if 1 == len(feedTar.URLs) || 1 == len(feedTar.IndexRegs) {
		return feedTar.IndexRegs
	}
	for i := 0; i < len(feedTar.URLs); i++ {
		if feedTar.URLs[i] == feedURL {
			return []*regexp.Regexp{feedTar.IndexRegs[i]}
		}
	}
	return nil
}

// FeedTarget should be generated by ParseJsonConfig function
// find content regexp
func FindContentReg(feedTar *FeedTarget, feedURL *url.URL, indexReg *regexp.Regexp) *regexp.Regexp {
	if nil == indexReg {
		return nil
	}

	urlNum := len(feedTar.URLs)
	indNum := len(feedTar.IndexRegs)

	if 1 == len(feedTar.ContentRegs) || (1 == urlNum && 1 == indNum) {
		return feedTar.ContentRegs[0]
	}

	if 1 == indNum && 1 != urlNum {
		for i := 0; i < urlNum; i++ {
			if feedTar.URLs[i] == feedURL {
				return feedTar.ContentRegs[i]
			}
		}
	} else {
		for i := 0; i < indNum; i++ {
			if feedTar.IndexRegs[i] == indexReg {
				return feedTar.ContentRegs[i]
			}
		}
	}

	return nil
}

func FindIndexFilterReg(feedTar *FeedTarget, indexReg *regexp.Regexp) *regexp.Regexp {
	if 1 == len(feedTar.IndexFilterRegs) {
		return feedTar.IndexFilterRegs[0]
	}

	for i := 0; i < len(feedTar.IndexRegs); i++ {
		if feedTar.IndexRegs[i] == indexReg {
			return feedTar.IndexFilterRegs[i]
		}
	}

	return nil
}

func FindContentFilterReg(feedTar *FeedTarget, contReg *regexp.Regexp) *regexp.Regexp {
	if 1 == len(feedTar.ContentFilterRegs) {
		return feedTar.ContentFilterRegs[0]
	}

	for i := 0; i < len(feedTar.ContentRegs); i++ {
		if feedTar.ContentRegs[i] == contReg {
			return feedTar.ContentFilterRegs[i]
		}
	}

	return nil
}

func FindPubDate(feedTar *FeedTarget, feedURL *url.URL) string {
	pubDateNum := len(feedTar.PubDateFormats)
	if 0 == pubDateNum {
		return ""
	} else if 1 == pubDateNum {
		return feedTar.PubDateFormats[0]
	}
	for i := 0; i < len(feedTar.URLs); i++ {
		if feedTar.URLs[i] == feedURL {
			return feedTar.PubDateFormats[i]
		}
	}
	return ""
}

// parse http Cache-Control response header
func ExtractMaxAge(cacheCtl string) (maxAge time.Duration) {
	for _, str := range strings.Split(cacheCtl, ",") {
		if strings.HasPrefix(str, "max-age") {
			maxAgeStrs := strings.Split(str, "=")
			if 2 != len(maxAgeStrs) {
				log.Printf("[ERROR] failed to parse max-age %s", str)
				return
			}
			maxAgeInt, err := strconv.Atoi(strings.TrimSpace(maxAgeStrs[1]))
			if nil != err {
				log.Printf("failed to convert max age string to int, originally %s, trimmed as %s: %s",
					maxAgeStrs[1], strings.TrimSpace(maxAgeStrs[1]), err)
			}
			return time.Duration(maxAgeInt)
		}
	}

	return
}

// get response http header
//func ExtractHttpResponseHeader(headers http.Header, headerName string) string {
//}

func ParsePubDate(formatStr, dateStr string) (time.Time, error) {
	pubdateValue := strings.TrimSpace(dateStr)
	pubDate, err := time.Parse(formatStr, pubdateValue)
	if nil != err {
		log.Printf("[ERROR] error parsing pubdate: %s, format is %s, real value is %s",
			err,
			formatStr,
			pubdateValue,
		)
		return time.Time{}, err
	} else {
		return time.Date(
			pubDate.Year(), pubDate.Month(), pubDate.Day(),
			pubDate.Hour(), pubDate.Minute(), pubDate.Second(), pubDate.Nanosecond(),
			GOFEED_DEFAULT_TIMEZONE,
		), nil
	}
}

func RemoveDuplicatEntries(feed *Feed) bool {
	if nil == feed {
		return false
	}

	entryMap := make(map[string]bool)
	newEntries := make([]*FeedEntry, 1)
	newEntryInd := 0

	for _, entry := range feed.Entries {
		link := entry.Link.String()
		if !entryMap[link] {
			entryMap[link] = true
			newEntries = append(newEntries[:newEntryInd], entry)
			newEntryInd += 1
		} else {
			log.Printf("[WARN] removed duplicate feed entry %s", entry.Link.String())
		}
	}

	feed.Entries = newEntries

	return true
}

func SetPubDates(feed *Feed) {
	for _, entry := range feed.Entries {
		if nil == entry {
			log.Printf("[ERROR] failed to set pubDate: entry is nil")
			return
		}
		if nil != entry.PubDate {
			continue
		} else if nil != entry.Cache.LastModified {
			entry.PubDate = entry.Cache.LastModified
		} else if nil != entry.Cache.Date {
			entry.PubDate = entry.Cache.Date
		} else {
			log.Printf("[ERROR] entry's cache date is nil %s", entry.Link.String())
			now := time.Now()
			entry.PubDate = &now
		}
	}
}
